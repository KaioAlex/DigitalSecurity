{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-088736b78776>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\security\\lib\\site-packages\\seaborn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtimeseries\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmiscplot\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0maxisgrid\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\security\\lib\\site-packages\\seaborn\\matrix.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhierarchy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\security\\lib\\site-packages\\scipy\\cluster\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'vq'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'hierarchy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhierarchy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_testutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPytestTester\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\security\\lib\\site-packages\\scipy\\cluster\\vq.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcdist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_vq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[0m__docformat__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'restructuredtext'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\security\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\security\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\security\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\security\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\security\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\security\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\security\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyod\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import preprocessing\n",
    "from pyod.utils.data import evaluate_print\n",
    "\n",
    "from pyod.models.pca import PCA\n",
    "from pyod.models.mcd import MCD\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "\n",
    "from pyod.models.lof import LOF \n",
    "from pyod.models.cof import COF\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.loci import LOCI\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.sod import SOD\n",
    "\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.sos import SOS\n",
    "\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.feature_bagging import FeatureBagging\n",
    "from pyod.models.lscp import LSCP\n",
    "\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "from pyod.models.so_gaal import SO_GAAL\n",
    "from pyod.models.mo_gaal import MO_GAAL\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from feature_selector import FeatureSelector\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = pd.read_csv('../Unbalanced_Samples/Sample_60K.csv',sep=',',header=0)\n",
    "\n",
    "import csv\n",
    "with open('../Unbalanced_Samples/Sample_60K.csv', newline='') as f:\n",
    "  csv_reader = csv.reader(f)\n",
    "  header = next(csv_reader)\n",
    "\n",
    "for i in range(len(header)):\n",
    "    header[i] = header[i]+\" (\"+str(i)+\")\"\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#transforma dados categóricos em números\n",
    "for f in testing_set.columns: \n",
    "    if testing_set[f].dtype=='object': \n",
    "        label = preprocessing.LabelEncoder() \n",
    "        label.fit(list(testing_set[f].values)) \n",
    "        testing_set[f] = label.transform(list(testing_set[f].values))\n",
    "    \n",
    "testingSet = testing_set.values\n",
    "np.random.shuffle(testingSet)\n",
    "\n",
    "testingSet = testingSet.astype(float)\n",
    "\n",
    "for i in range (6*10**4-1, 0, -1):\n",
    "    for j in range(0, 6):\n",
    "        testingSet[i, j] = float(testingSet[i, j])\n",
    "        if (np.isinf(testingSet[i, j]) or np.isnan(testingSet[i, j])):\n",
    "            testingSet = np.delete(testingSet, i, axis=0)\n",
    "\n",
    "y_test = testingSet[:, 84].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.subplots(figsize=(10, 3))\n",
    "distribution = pd.DataFrame({\"Classificação\": [\"DDoS\",\"Benigno\"],\n",
    "                             \"Quantidade\":  [y_test.sum() , y_test.size - y_test.sum()]})\n",
    "sns.barplot(data=distribution, y=\"Classificação\", x=\"Quantidade\").set_title(\"Distribuição Classificativa\", fontsize=25)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salva os sets originais\n",
    "original_testingSet = testingSet\n",
    "original_testingSet = np.delete(original_testingSet, 84, axis=1)\n",
    "original_header = header\n",
    "original_header = np.delete(original_header, 84, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = pd.DataFrame(testingSet)\n",
    "testing_set.columns = header\n",
    "corrmat = testing_set.corr()\n",
    "top_corr_features = corrmat.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features codificadas pelo label enconder: 17 16 7 4 2 1 0\n",
    "#Feaatures sempre 0: 67, 66, 65, 64, 63, 62, 40, 39\n",
    "#features com correlação próxima de zero, vide loop abaixo: 73, 71, 70, 50, 42, 34, 12, 10 \n",
    "\n",
    "droppingList = [67, 66, 65, 64, 63, 62, 40, 39]\n",
    "droppedFeatures = droppingList\n",
    "\n",
    "cm = testing_set[top_corr_features].corr().values\n",
    "for i in (droppingList):\n",
    "    testingSet = np.delete(testingSet, i, axis=1)\n",
    "    header = np.delete(header, i, axis=0)\n",
    "    \n",
    "    cm = np.delete(cm, i, axis = 0)\n",
    "    cm = np.delete(cm, i, axis = 1)\n",
    "\n",
    "tolerance = 0.4\n",
    "for i in range(cm.shape[0]-1, 0, -1):\n",
    "    if cm[cm.shape[0]-1, i] >= -tolerance and cm[cm.shape[0]-1, i] <= tolerance:\n",
    "        if i not in droppingList:\n",
    "            droppedFeatures.append(i)\n",
    "            testingSet = np.delete(testingSet, i, axis=1)\n",
    "            header = np.delete(header, i, axis=0)\n",
    "print(\"Features dropadas: \")\n",
    "print(droppedFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = pd.DataFrame(testingSet)\n",
    "testing_set.columns = header\n",
    "corrmat = testing_set.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(testingSet.shape[1], testingSet.shape[1]))\n",
    "#plot heat map\n",
    "g=sns.heatmap(testing_set[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n",
    "g.set_ylim(g.get_ylim()[0]+0.5, g.get_ylim()[1]-0.5)\n",
    "\n",
    "testingSet = np.delete(testingSet, 84-len(droppedFeatures), axis=1)  #deleta o label\n",
    "header = np.delete(header, 84-len(droppedFeatures), axis=0)\n",
    "\n",
    "labelCorrelation_testingSet = testingSet\n",
    "labelCorrelation_header = header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = pd.DataFrame(testingSet)\n",
    "testing_set.columns = header\n",
    "fs = FeatureSelector(data = testing_set, labels = y_test)\n",
    "fs.identify_collinear(correlation_threshold = 0.85)\n",
    "\n",
    "#gets real indexes of collinear above threshold features\n",
    "real_indexs = np.zeros(fs.record_collinear.shape[0])\n",
    "j = 0\n",
    "for i in range(header.size):\n",
    "    if (header[i] == fs.record_collinear.iloc[j, 0]):\n",
    "        real_indexs[j] = i\n",
    "        j = j+1\n",
    "\n",
    "real_indexs = np.unique(real_indexs)\n",
    "for i in range(real_indexs.size - 1, -1, -1):\n",
    "    np.delete(testingSet, real_indexs[i], axis = 1)\n",
    "\n",
    "print(real_indexs)\n",
    "fs.record_collinear.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplica a padronização z-score\n",
    "\"\"\"testingSetSaved = testingSet\n",
    "\n",
    "mi = np.mean(testingSet)\n",
    "sigma = np.std(testingSet)\n",
    "testingSet = (testingSet - mi) / sigma\"\"\"\n",
    "\n",
    "#Aplica regularização default sk-learn\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(testingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_fraction = 0.17\n",
    "def testMethod(clf, clf_name):\n",
    "    clf.fit(testingSet)\n",
    "\n",
    "    #####################################################################\n",
    "\n",
    "    y_test_pred = clf.predict(testingSet)  # outlier labels (0 or 1)\n",
    "    y_test_scores = clf.decision_function(testingSet)  # outlier scores\n",
    "\n",
    "    #####################################################################\n",
    "\n",
    "    print(\"\\nOn Test Data - \"+clf_name+\":\")\n",
    "    truePositive = 0\n",
    "    trueNegative = 0\n",
    "    falsePositive = 0\n",
    "    falseNegative = 0\n",
    "\n",
    "    for i in range(y_test.size):\n",
    "        if(y_test[i] == 1 and y_test_pred[i] == 1):\n",
    "            truePositive = truePositive+1\n",
    "        elif (y_test[i] == 0 and y_test_pred[i] == 0):\n",
    "            trueNegative = trueNegative+1\n",
    "        elif (y_test[i] == 0 and y_test_pred[i] == 1):\n",
    "            falsePositive = falsePositive+1\n",
    "        else:\n",
    "            falseNegative = falseNegative+1\n",
    "\n",
    "    print(truePositive, \" | \", falsePositive)\n",
    "    print(falseNegative, \" | \", trueNegative,\"\\n\")\n",
    "\n",
    "    evaluate_print(clf_name, y_test, y_test_scores)\n",
    "\n",
    "    #####################################################################\n",
    "\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, y_test_scores)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.title('Receiver Operating Characteristic - '+clf_name)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    \n",
    "    #gets usual metrics based on results obtained\n",
    "    total = y_test.shape[0]\n",
    "    \n",
    "    accuracy = (truePositive+trueNegative)/total\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    \n",
    "    if(truePositive+falsePositive != 0):\n",
    "        precision = truePositive/(truePositive+falsePositive)\n",
    "        print(\"Precision: \", precision)\n",
    "    else:\n",
    "        precision = 0\n",
    "        print(\"Precision: -\")\n",
    "        \n",
    "    if(truePositive+falseNegative != 0):\n",
    "        recall = truePositive/(truePositive+falseNegative)\n",
    "        print(\"Recall: \", recall)\n",
    "    else:\n",
    "        recall = 0\n",
    "        print(\"Recall: -\")\n",
    "        \n",
    "    if(recall + precision != 0):\n",
    "        f1 = 2*(recall*precision)/(recall+precision)\n",
    "        print(\"F1-score: \", f1)\n",
    "    else:\n",
    "        print(\"F1-score: -\")\n",
    "        \n",
    "    print(\"Duration\": )\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Linear Models\n",
    "classifiers = {\n",
    "    'PCA': PCA(contamination= outliers_fraction),\n",
    "    'MCD': MCD(contamination= outliers_fraction),\n",
    "    'OCSVM': OCSVM(contamination= outliers_fraction)\n",
    "}\n",
    "\n",
    "for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "    testMethod(clf, clf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Proximity Based\n",
    "classifiers = {\n",
    "    #'COF': COF(contamination= outliers_fraction),  #Apresentou erros de execução.\n",
    "    'LOF': LOF(contamination = outliers_fraction),\n",
    "    'CBLOF':CBLOF(contamination= outliers_fraction),\n",
    "    #'LOCI':LOCI(contamination= outliers_fraction),   #Travou a máquina de execução repetidas vezes.\n",
    "    'HBOS': HBOS(contamination= outliers_fraction),\n",
    "    'kNN': KNN(method='largest', contamination= outliers_fraction),\n",
    "    'AvgKNN': KNN(method='mean', contamination= outliers_fraction),\n",
    "    'MedKNN': KNN(method='median', contamination= outliers_fraction),\n",
    "    'SOD': SOD(contamination= outliers_fraction)\n",
    "}\n",
    "\n",
    "for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "    testMethod(clf, clf_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Probabilistic tests\n",
    "classifiers = {\n",
    "    'ABOD': ABOD(contamination = outliers_fraction),\n",
    "    #'SOS': SOS(contamination = outliers_fraction) #Apresentou erros de execução.\n",
    "}\n",
    "\n",
    "for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "    testMethod(clf, clf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensenbles tests\n",
    "listDetectors = detector_list=[HBOS(),\n",
    "                               PCA(),\n",
    "                               ABOD(),\n",
    "                               LOF(),\n",
    "                               KNN()]\n",
    "classifiers = {\n",
    "    'Isolation Forest': IForest(contamination = outliers_fraction),\n",
    "    'Feature Bagging': FeatureBagging(contamination = outliers_fraction)\n",
    "    #'LSCP': LSCP(detector_list = listDetectors, contamination = outliers_fraction) #Still couldn't get it to work\n",
    "    #XGBOD tests are in a separate file\n",
    "}\n",
    "\n",
    "for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "    testMethod(clf, clf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Neural Networks tests\n",
    "classifiers = {\n",
    "    'AutoEncoder': AutoEncoder(contamination = outliers_fraction, hidden_neurons = [8, 4, 4, 8], epochs = 15),\n",
    "    'SO_GAAL': SO_GAAL(contamination = outliers_fraction),\n",
    "    'MO_GAAL': MO_GAAL(contamination = outliers_fraction)\n",
    "}\n",
    "\n",
    "for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "    testMethod(clf, clf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
